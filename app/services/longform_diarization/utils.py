import json
from pathlib import Path, PosixPath

import nltk
from omegaconf import OmegaConf


def create_config(
    audio_file_path: PosixPath,
    temp_dir: PosixPath,
    manifest_filepath: PosixPath,
    domain: str = "telephonic",
    _diarization_kwards: dict | None = None,
    input_manifest_kwargs: dict | None = None,
) -> OmegaConf:
    """
    Create config for diarization.

    Args:
        audio_file_path (str): Path to audio file.
        temp_dir (str): Path to temp directory.
        manifest_filepath (str): Path to manifest file.
        domain (str): Domain of the audio file.
        diarization_kwards (dict): Diarization kwargs.
        input_manifest_kwargs (dict): Input manifest kwargs.

    Returns:
        OmegaConf: Config for diarization.
    """
    config_path = Path(__file__).parent / "configs" / f"{domain}.json"
    with Path.open(config_path, "r") as f:
        general_conf = json.load(f)

    config = OmegaConf.create(general_conf)

    meta = {
        "audio_filepath": str(audio_file_path),
        "offset": 0,
        "duration": None,
        "label": "infer",
        "text": "-",
        "rttm_filepath": None,
        "uem_filepath": None,
    }

    if input_manifest_kwargs:
        meta.update(input_manifest_kwargs)

    with Path.open(manifest_filepath, "w") as fp:
        json.dump(meta, fp)
        fp.write("\n")

    config.diarizer.manifest_filepath = str(manifest_filepath)
    config.diarizer.out_dir = str(temp_dir)
    config.diarizer.oracle_vad = False
    config.diarizer.clustering.parameters.oracle_num_speakers = False

    # _TODO: Add all diarization kwargs to config
    config.diarizer.vad.parameters.onset = 0.8
    config.diarizer.vad.parameters.offset = 0.6
    config.diarizer.vad.parameters.pad_offset = -0.05
    config.diarizer.msdd_model.model_path = "diar_msdd_telephonic"

    return config


def get_word_ts_anchor(s: int, e: int, option: str = "start") -> float:
    if option == "end":
        return e
    elif option == "mid":
        return (s + e) / 2
    return s


def get_words_speaker_mapping(wrd_ts: list[dict], spk_ts: list, word_anchor_option: str = "start") -> list:
    s, e, sp = spk_ts[0]
    wrd_pos, turn_idx = 0, 0
    wrd_spk_mapping = []
    for wrd_dict in wrd_ts:
        ws, we, wrd = (
            int(wrd_dict["start"] * 1000),
            int(wrd_dict["end"] * 1000),
            wrd_dict["word"],
        )
        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)
        while wrd_pos > float(e):
            turn_idx += 1
            turn_idx = min(turn_idx, len(spk_ts) - 1)
            s, e, sp = spk_ts[turn_idx]
            if turn_idx == len(spk_ts) - 1:
                e = get_word_ts_anchor(ws, we, option="end")
        wrd_spk_mapping.append({"word": wrd, "start_time": ws, "end_time": we, "speaker": sp})
    return wrd_spk_mapping


def get_first_word_idx_of_sentence(word_idx: int, word_list: list[str], speaker_list: list[str], max_words: int) -> int:
    def is_word_sentence_end(x: int) -> bool:
        return x >= 0 and word_list[x][-1] in ".?!"

    left_idx = word_idx
    while (
        left_idx > 0
        and word_idx - left_idx < max_words
        and speaker_list[left_idx - 1] == speaker_list[left_idx]
        and not is_word_sentence_end(left_idx - 1)
    ):
        left_idx -= 1

    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1


def get_last_word_idx_of_sentence(word_idx: int, word_list: list[str], max_words: int) -> int:
    def is_word_sentence_end(x: int) -> bool:
        return x >= 0 and word_list[x][-1] in ".?!"

    right_idx = word_idx
    while right_idx < len(word_list) and right_idx - word_idx < max_words and not is_word_sentence_end(right_idx):
        right_idx += 1

    return right_idx if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx) else -1


def get_realigned_ws_mapping_with_punctuation(word_speaker_mapping: list, max_words_in_sentence: int = 50) -> list:
    def is_word_sentence_end(x: int) -> bool:
        return x >= 0 and word_speaker_mapping[x]["word"][-1] in ".?!"

    wsp_len = len(word_speaker_mapping)

    words_list, speaker_list = [], []
    for _k, line_dict in enumerate(word_speaker_mapping):
        word, speaker = line_dict["word"], line_dict["speaker"]
        words_list.append(word)
        speaker_list.append(speaker)

    k = 0
    while k < len(word_speaker_mapping):
        line_dict = word_speaker_mapping[k]
        if k < wsp_len - 1 and speaker_list[k] != speaker_list[k + 1] and not is_word_sentence_end(k):
            left_idx = get_first_word_idx_of_sentence(k, words_list, speaker_list, max_words_in_sentence)
            right_idx = (
                get_last_word_idx_of_sentence(k, words_list, max_words_in_sentence - k + left_idx - 1)
                if left_idx > -1
                else -1
            )
            if min(left_idx, right_idx) == -1:
                k += 1
                continue

            spk_labels = speaker_list[left_idx : right_idx + 1]
            mod_speaker = max(set(spk_labels), key=spk_labels.count)
            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:
                k += 1
                continue

            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (right_idx - left_idx + 1)
            k = right_idx

        k += 1

    k, realigned_list = 0, []
    while k < len(word_speaker_mapping):
        line_dict = word_speaker_mapping[k].copy()
        line_dict["speaker"] = speaker_list[k]
        realigned_list.append(line_dict)
        k += 1

    return realigned_list


def get_sentences_speaker_mapping(word_speaker_mapping: list, spk_ts: list) -> list:
    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak
    s, e, spk = spk_ts[0]
    prev_spk = spk

    snts = []
    snt = {"speaker": f"Speaker {spk}", "start_time": s, "end_time": e, "text": ""}

    for wrd_dict in word_speaker_mapping:
        wrd, spk = wrd_dict["word"], wrd_dict["speaker"]
        s, e = wrd_dict["start_time"], wrd_dict["end_time"]
        if spk != prev_spk or sentence_checker(snt["text"] + " " + wrd):
            snts.append(snt)
            snt = {
                "speaker": f"Speaker {spk}",
                "start_time": s,
                "end_time": e,
                "text": "",
            }
        else:
            snt["end_time"] = e
        snt["text"] += wrd + " "
        prev_spk = spk

    snts.append(snt)
    return snts


def get_speaker_aware_transcript(sentences_speaker_mapping: list) -> list:
    transcript = []
    previous_speaker = sentences_speaker_mapping[0]["speaker"]
    transcript.append(f"{previous_speaker}: ")

    for sentence_dict in sentences_speaker_mapping:
        speaker = sentence_dict["speaker"]
        sentence = sentence_dict["text"]

        # If this speaker doesn't match the previous one, start a new paragraph
        if speaker != previous_speaker:
            transcript.append(f"\n\n{speaker}: ")
            previous_speaker = speaker

        # No matter what, write the current sentence
        transcript.append(sentence + " ")
    return transcript
